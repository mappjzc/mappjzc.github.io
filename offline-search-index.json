[{"body":" If you only plan to run the product locally, this is the ONLY section you should need. Commands written like this are to be run in your terminal.  Required Packages to Install  Docker docker-compose  NOTE: After installing docker, you may need to run the docker application and restart your terminal\nCommands to run in your terminal IMPORTANT: DevLake doesn’t support Database Schema Migration yet, upgrading an existing instance is likely to break, we recommend that you deploy a new instance instead.\n  Download docker-compose.yml and env.example from latest release page into a folder.\n  Rename env.example to .env. For Mac/Linux users, please run mv env.example .env in the terminal.\n  Start Docker on your machine, then run docker-compose up -d to start the services.\n  Visit localhost:4000 to set up configuration files.\n  Navigate to desired plugins on the Integrations page Please reference the following for more details on how to configure each one:\nJira\nGitLab\nJenkins\nGitHub\n Submit the form to update the values by clicking on the Save Connection button on each form page devlake takes a while to fully boot up. if config-ui complaining about api being unreachable, please wait a few seconds and try refreshing the page.     Visit localhost:4000/pipelines/create to RUN a Pipeline and trigger data collection.\nPipelines Runs can be initiated by the new “Create Run” Interface. Simply enable the Data Source Providers you wish to run collection for, and specify the data you want to collect, for instance, Project ID for Gitlab and Repository Name for GitHub.\nOnce a valid pipeline configuration has been created, press Create Run to start/run the pipeline. After the pipeline starts, you will be automatically redirected to the Pipeline Activity screen to monitor collection activity.\nPipelines is accessible from the main menu of the config-ui for easy access.\n Manage All Pipelines: http://localhost:4000/pipelines Create Pipeline RUN: http://localhost:4000/pipelines/create Track Pipeline Activity: http://localhost:4000/pipelines/activity/[RUN_ID]  For advanced use cases and complex pipelines, please use the Raw JSON API to manually initiate a run using cURL or graphical API tool such as Postman. POST the following request to the DevLake API Endpoint.\n[  [  {  \"plugin\": \"github\",  \"options\": {  \"repo\": \"lake\",  \"owner\": \"merico-dev\"  }  }  ] ] Please refer to this wiki How to trigger data collection.\n  Click View Dashboards button in the top left when done, or visit localhost:3002 (username: admin, password: admin).\nWe use Grafana as a visualization tool to build charts for the data stored in our database. Using SQL queries, we can add panels to build, save, and edit customized dashboards.\nAll the details on provisioning and customizing a dashboard can be found in the Grafana Doc.\n  Setup cron job To synchronize data periodically, we provide lake-cli for easily sending data collection requests along with a cron job to periodically trigger the cli tool. ","categories":"","description":"The steps to install DevLake locally.\n","excerpt":"The steps to install DevLake locally.\n","ref":"/docs/quick-start/1.localsetup/","tags":"","title":"Local Setup"},{"body":" If you only plan to run the product locally, this is the ONLY section you should need. Commands written like this are to be run in your terminal.  Required Packages to Install  Docker docker-compose  NOTE: After installing docker, you may need to run the docker application and restart your terminal\nCommands to run in your terminal IMPORTANT: DevLake doesn’t support Database Schema Migration yet, upgrading an existing instance is likely to break, we recommend that you deploy a new instance instead.\n  Download docker-compose.yml and env.example from latest release page into a folder.\n  Rename env.example to .env. For Mac/Linux users, please run mv env.example .env in the terminal.\n  Start Docker on your machine, then run docker-compose up -d to start the services.\n  Visit localhost:4000 to set up configuration files.\n  Navigate to desired plugins on the Integrations page Please reference the following for more details on how to configure each one:\nJira\nGitLab\nJenkins\nGitHub\n Submit the form to update the values by clicking on the Save Connection button on each form page devlake takes a while to fully boot up. if config-ui complaining about api being unreachable, please wait a few seconds and try refreshing the page.     Visit localhost:4000/pipelines/create to RUN a Pipeline and trigger data collection.\nPipelines Runs can be initiated by the new “Create Run” Interface. Simply enable the Data Source Providers you wish to run collection for, and specify the data you want to collect, for instance, Project ID for Gitlab and Repository Name for GitHub.\nOnce a valid pipeline configuration has been created, press Create Run to start/run the pipeline. After the pipeline starts, you will be automatically redirected to the Pipeline Activity screen to monitor collection activity.\nPipelines is accessible from the main menu of the config-ui for easy access.\n Manage All Pipelines: http://localhost:4000/pipelines Create Pipeline RUN: http://localhost:4000/pipelines/create Track Pipeline Activity: http://localhost:4000/pipelines/activity/[RUN_ID]  For advanced use cases and complex pipelines, please use the Raw JSON API to manually initiate a run using cURL or graphical API tool such as Postman. POST the following request to the DevLake API Endpoint.\n[  [  {  \"plugin\": \"github\",  \"options\": {  \"repo\": \"lake\",  \"owner\": \"merico-dev\"  }  }  ] ] Please refer to this wiki How to trigger data collection.\n  Click View Dashboards button in the top left when done, or visit localhost:3002 (username: admin, password: admin).\nWe use Grafana as a visualization tool to build charts for the data stored in our database. Using SQL queries, we can add panels to build, save, and edit customized dashboards.\nAll the details on provisioning and customizing a dashboard can be found in the Grafana Doc.\n  Setup cron job To synchronize data periodically, we provide lake-cli for easily sending data collection requests along with a cron job to periodically trigger the cli tool. ","categories":"","description":"The steps to install DevLake locally.\n","excerpt":"The steps to install DevLake locally.\n","ref":"/zh/docs/quick-start/1.localsetup/","tags":"","title":"Local Setup"},{"body":"DevLake brings your DevOps data into one practical, customized, extensible view. Ingest, analyze, and visualize data from an ever-growing list of developer tools, with our open source product.\nDevLake is designed for developer teams looking to make better sense of their development process and to bring a more data-driven approach to their own practices. You can ask DevLake many questions regarding your development process. Just connect and query.\nSee demo. Username/password:test/test. The demo is based on the data from this repo, merico-dev/lake.\nUser Flow\nWhat can be accomplished with DevLake?  Collect DevOps data across the entire SDLC process and connect data silos. A standard data model and out-of-the-box metrics for software engineering. Flexible framework for data collection and ETL, support customized analysis.   ","categories":"","description":"General introduction of DevLake\n","excerpt":"General introduction of DevLake\n","ref":"/docs/overview/1.whatisdevlake/","tags":"","title":"What is DevLake?"},{"body":"DevLake brings your DevOps data into one practical, customized, extensible view. Ingest, analyze, and visualize data from an ever-growing list of developer tools, with our open source product.\nDevLake is designed for developer teams looking to make better sense of their development process and to bring a more data-driven approach to their own practices. You can ask DevLake many questions regarding your development process. Just connect and query.\nSee demo. Username/password:test/test. The demo is based on the data from this repo, merico-dev/lake.\nUser Flow\nWhat can be accomplished with DevLake?  Collect DevOps data across the entire SDLC process and connect data silos. A standard data model and out-of-the-box metrics for software engineering. Flexible framework for data collection and ETL, support customized analysis.   ","categories":"","description":"General introduction of DevLake\n","excerpt":"General introduction of DevLake\n","ref":"/zh/docs/overview/1.whatisdevlake/","tags":"","title":"What is DevLake?"},{"body":"Architecture Diagram\nStack (from low to high)  config logger models plugins services api / cli  Rules  Higher layer calls lower layer, not the other way around Whenever lower layer neeeds something from higher layer, a interface should be introduced for decoupling Components should be initialized in a low to high order during bootstraping   ","categories":"","description":"Understand the architecture of DevLake.\n","excerpt":"Understand the architecture of DevLake.\n","ref":"/docs/overview/2.architecture/","tags":"","title":"Architecture"},{"body":"Architecture Diagram\nStack (from low to high)  config logger models plugins services api / cli  Rules  Higher layer calls lower layer, not the other way around Whenever lower layer neeeds something from higher layer, a interface should be introduced for decoupling Components should be initialized in a low to high order during bootstraping   ","categories":"","description":"Understand the architecture of DevLake.\n","excerpt":"Understand the architecture of DevLake.\n","ref":"/zh/docs/overview/2.architecture/","tags":"","title":"Architecture"},{"body":"","categories":"","description":"The steps to install DevLake in Kubernetes.\n","excerpt":"The steps to install DevLake in Kubernetes.\n","ref":"/docs/quick-start/2.kubernetessetup/","tags":"","title":"Kubernetes Setup"},{"body":"","categories":"","description":"The steps to install DevLake in Kubernetes.\n","excerpt":"The steps to install DevLake in Kubernetes.\n","ref":"/zh/docs/quick-start/2.kubernetessetup/","tags":"","title":"Kubernetes Setup"},{"body":"Requirements  Docker Golang v1.17+ Make  Mac (Already installed) Windows: Download Ubuntu: sudo apt-get install build-essential    How to setup dev environment   Navigate to where you would like to install this project and clone the repository:\ngit clone https://github.com/merico-dev/lake.git cd lake   Install dependencies for plugins:\n RefDiff    Install Go packages\ngo get   Copy the sample config file to new local file:\ncp .env.example .env   Update the following variables in the file .env:\n DB_URL: Replace mysql:3306 with 127.0.0.1:3306    Start the MySQL and Grafana containers:\n Make sure the Docker daemon is running before this step.\n docker-compose up -d mysql grafana   Run lake and config UI in dev mode in two seperate terminals:\n# run lake make dev # run config UI make configure-dev   Visit config UI at localhost:4000 to configure data sources.\n  Navigate to desired plugins pages on the Integrations page You will need to enter the required information for the plugins you intend to use. Please reference the following for more details on how to configure each one: -\u003e Jira -\u003e GitLab, -\u003e Jenkins -\u003e GitHub     Submit the form to update the values by clicking on the Save Connection button on each form page     Visit localhost:4000/pipelines/create to RUN a Pipeline and trigger data collection.\nPipelines Runs can be initiated by the new “Create Run” Interface. Simply enable the Data Source Providers you wish to run collection for, and specify the data you want to collect, for instance, Project ID for Gitlab and Repository Name for GitHub.\nOnce a valid pipeline configuration has been created, press Create Run to start/run the pipeline. After the pipeline starts, you will be automatically redirected to the Pipeline Activity screen to monitor collection activity.\nPipelines is accessible from the main menu of the config-ui for easy access.\n Manage All Pipelines: http://localhost:4000/pipelines Create Pipeline RUN: http://localhost:4000/pipelines/create Track Pipeline Activity: http://localhost:4000/pipelines/activity/[RUN_ID]  For advanced use cases and complex pipelines, please use the Raw JSON API to manually initiate a run using cURL or graphical API tool such as Postman. POST the following request to the DevLake API Endpoint.\n[  [  {  \"plugin\": \"github\",  \"options\": {  \"repo\": \"lake\",  \"owner\": \"merico-dev\"  }  }  ] ] Please refer to this wiki How to trigger data collection.\n  Click View Dashboards button in the top left when done, or visit localhost:3002 (username: admin, password: admin).\nWe use Grafana as a visualization tool to build charts for the data stored in our database. Using SQL queries, we can add panels to build, save, and edit customized dashboards.\nAll the details on provisioning and customizing a dashboard can be found in the Grafana Doc.\n  (Optional) To run the tests:\nmake test   \n","categories":"","description":"The steps to install DevLake in develper mode.\n","excerpt":"The steps to install DevLake in develper mode.\n","ref":"/docs/quick-start/3.developersetup/","tags":"","title":"Developer Setup"},{"body":"Requirements  Docker Golang v1.17+ Make  Mac (Already installed) Windows: Download Ubuntu: sudo apt-get install build-essential    How to setup dev environment   Navigate to where you would like to install this project and clone the repository:\ngit clone https://github.com/merico-dev/lake.git cd lake   Install dependencies for plugins:\n RefDiff    Install Go packages\ngo get   Copy the sample config file to new local file:\ncp .env.example .env   Update the following variables in the file .env:\n DB_URL: Replace mysql:3306 with 127.0.0.1:3306    Start the MySQL and Grafana containers:\n Make sure the Docker daemon is running before this step.\n docker-compose up -d mysql grafana   Run lake and config UI in dev mode in two seperate terminals:\n# run lake make dev # run config UI make configure-dev   Visit config UI at localhost:4000 to configure data sources.\n  Navigate to desired plugins pages on the Integrations page You will need to enter the required information for the plugins you intend to use. Please reference the following for more details on how to configure each one: -\u003e Jira -\u003e GitLab, -\u003e Jenkins -\u003e GitHub     Submit the form to update the values by clicking on the Save Connection button on each form page     Visit localhost:4000/pipelines/create to RUN a Pipeline and trigger data collection.\nPipelines Runs can be initiated by the new “Create Run” Interface. Simply enable the Data Source Providers you wish to run collection for, and specify the data you want to collect, for instance, Project ID for Gitlab and Repository Name for GitHub.\nOnce a valid pipeline configuration has been created, press Create Run to start/run the pipeline. After the pipeline starts, you will be automatically redirected to the Pipeline Activity screen to monitor collection activity.\nPipelines is accessible from the main menu of the config-ui for easy access.\n Manage All Pipelines: http://localhost:4000/pipelines Create Pipeline RUN: http://localhost:4000/pipelines/create Track Pipeline Activity: http://localhost:4000/pipelines/activity/[RUN_ID]  For advanced use cases and complex pipelines, please use the Raw JSON API to manually initiate a run using cURL or graphical API tool such as Postman. POST the following request to the DevLake API Endpoint.\n[  [  {  \"plugin\": \"github\",  \"options\": {  \"repo\": \"lake\",  \"owner\": \"merico-dev\"  }  }  ] ] Please refer to this wiki How to trigger data collection.\n  Click View Dashboards button in the top left when done, or visit localhost:3002 (username: admin, password: admin).\nWe use Grafana as a visualization tool to build charts for the data stored in our database. Using SQL queries, we can add panels to build, save, and edit customized dashboards.\nAll the details on provisioning and customizing a dashboard can be found in the Grafana Doc.\n  (Optional) To run the tests:\nmake test   \n","categories":"","description":"The steps to install DevLake in develper mode.\n","excerpt":"The steps to install DevLake in develper mode.\n","ref":"/zh/docs/quick-start/3.developersetup/","tags":"","title":"Developer Setup"},{"body":"Goals  Moving to Apache Incubator and making DevLake a graduation-ready project. Explore and implement 3 typical use scenarios to help certain engineering teams and developers:  Observation of open-source project contribution and quality DORA metrics for the DevOps team SDLC workflow monitoring and improvement   Better UX for end-users and contributors.  DevLake 2022 Roadmap DevLake is currently under rapid development. This page describes the project’s public roadmap, the result of an ongoing collaboration between the core maintainers and the broader DevLake community.\nThis roadmap is broken down by the goals in the last section.\n   Category Features     More data sources across different DevOps domains 1. Issue/Task Management - Jira server 2. Issue/Task Management - Jira data center 3. Issue/Task Management - GitLab Issues 4. Issue/Task Management - Trello 5. Issue/Task Management - TPAD 6. Issue/Task Management - Teambition 7. Issue/Task Management - Trello 8. Source Code Management - GitLab on-premise 9. Source Code Management - BitBucket 10. Source Code Management - Gitee 11. Code Review - Gerrit 12. Code Review - GitLab on-premise MRs 13. CI/CD - GitHub Action 14. CI/CD - ArgoCI 15. CI/CD - ArgoCD 16. CI/CD - TeamCity 17. Quality - SonarQube 18. Quality - Fossa 19. QA - Selenium 20. QA - Junit 21. QA - JMeter 22. QA - Cucumber test 23. Calendar - Google Calendar 24. Calendar - Zoom Calendar 25. Calendar - Lark Calendar 26. Calendar - Tencent Calendar 27. Other - GitHub stars, clones, watches    More comprehensive and flexible engineering data model 1. complete and polish standard data models for different DevOps domains 2. allow users to modify standard tables 3. allow users to create new tables 4. allow users to easily define ETL rules    Better UX 1. improve config-UI design for better onboard experience 2. improve data collection speed for Github and other plugins with strict API rate limit 3. build a website to present well-organized documentation to DevLake users and contributors     How to Influence Roadmap A roadmap is only useful when it captures real user needs. We are glad to hear from you if you have specific use cases, feedback, or ideas. You can submit an issue to let us know! Also, if you plan to work (or are already working) on a new or existing feature, tell us, so that we can update the roadmap accordingly. We are happy to share knowledge and context to help your feature land successfully. ","categories":"","description":"The goals and roadmap for DevLake in 2022.\n","excerpt":"The goals and roadmap for DevLake in 2022.\n","ref":"/docs/overview/3.roadmap/","tags":"","title":"Roadmap"},{"body":"Goals  Moving to Apache Incubator and making DevLake a graduation-ready project. Explore and implement 3 typical use scenarios to help certain engineering teams and developers:  Observation of open-source project contribution and quality DORA metrics for the DevOps team SDLC workflow monitoring and improvement   Better UX for end-users and contributors.  DevLake 2022 Roadmap DevLake is currently under rapid development. This page describes the project’s public roadmap, the result of an ongoing collaboration between the core maintainers and the broader DevLake community.\nThis roadmap is broken down by the goals in the last section.\n   Category Features     More data sources across different DevOps domains 1. Issue/Task Management - Jira server 2. Issue/Task Management - Jira data center 3. Issue/Task Management - GitLab Issues 4. Issue/Task Management - Trello 5. Issue/Task Management - TPAD 6. Issue/Task Management - Teambition 7. Issue/Task Management - Trello 8. Source Code Management - GitLab on-premise 9. Source Code Management - BitBucket 10. Source Code Management - Gitee 11. Code Review - Gerrit 12. Code Review - GitLab on-premise MRs 13. CI/CD - GitHub Action 14. CI/CD - ArgoCI 15. CI/CD - ArgoCD 16. CI/CD - TeamCity 17. Quality - SonarQube 18. Quality - Fossa 19. QA - Selenium 20. QA - Junit 21. QA - JMeter 22. QA - Cucumber test 23. Calendar - Google Calendar 24. Calendar - Zoom Calendar 25. Calendar - Lark Calendar 26. Calendar - Tencent Calendar 27. Other - GitHub stars, clones, watches    More comprehensive and flexible engineering data model 1. complete and polish standard data models for different DevOps domains 2. allow users to modify standard tables 3. allow users to create new tables 4. allow users to easily define ETL rules    Better UX 1. improve config-UI design for better onboard experience 2. improve data collection speed for Github and other plugins with strict API rate limit 3. build a website to present well-organized documentation to DevLake users and contributors     How to Influence Roadmap A roadmap is only useful when it captures real user needs. We are glad to hear from you if you have specific use cases, feedback, or ideas. You can submit an issue to let us know! Also, if you plan to work (or are already working) on a new or existing feature, tell us, so that we can update the roadmap accordingly. We are happy to share knowledge and context to help your feature land successfully. ","categories":"","description":"The goals and roadmap for DevLake in 2022.\n","excerpt":"The goals and roadmap for DevLake in 2022.\n","ref":"/zh/docs/overview/3.roadmap/","tags":"","title":"Roadmap"},{"body":"👍🎉 First off, thanks for taking the time to contribute! 🎉👍\nThe following is a set of guidelines for contributing to Lake. These are mostly guidelines, not rules. Use your best judgment, and feel free to propose changes to this document in a pull request.*\nHow Can I Contribute?   Reporting bugs by filling out the required issue template and labeling the new issue as ‘bug’.\n  Suggesting enhancements.\n  If you intend to change the public API, or make any non-trivial changes to the implementation, we recommend filing an issue. This lets us reach an agreement on your proposal before you put significant effort into it.\nIf you’re only fixing a bug, it’s fine to submit a pull request right away but we still recommend to file an issue detailing what you’re fixing. This is helpful in case we don’t accept that specific fix but want to keep track of the issue.\nMaintainer team @ Merico Dev Lake is maintained by a group of engineers at Merico, led by @hezyin. We aim to achieve an SLA of 24 hrs for replying to issues.\nStyle guides Git Commit message We follow the conventional commits guidelines.\nCommit tool We use https://github.com/lintingzhen/commitizen-go to author our commits.\nmake commit \u003e lake@1.0.0 commit /home/code/merico-dev/lake \u003e cz cz-cli@4.2.4, cz-conventional-changelog@3.3.0 ? Select the type of change that you're committing: (Use arrow keys) \u003e feat: A new feature fix: A bug fix docs: Documentation only changes style: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc) refactor: A code change that neither fixes a bug nor adds a feature perf: A code change that improves performance test: Adding missing tests or correcting existing tests (Move up and down to reveal more choices) ? What is the scope of this change (e.g. component or file name): (press enter to skip) ? Write a short, imperative tense description of the change (max 93 chars): (23) add commit message tool ? Provide a longer description of the change: (press enter to skip) ? Are there any breaking changes? No ? Does this change affect any open issues? No [chore/commit_message dc34f57] chore: add commit message tool 5 files changed, 585 insertions(+), 4 deletions(-) \n","categories":"","description":"The steps and specs to contribute to DevLake.\n","excerpt":"The steps and specs to contribute to DevLake.\n","ref":"/community/contribution/","tags":"","title":"How to Make Contribution?"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/overview/","tags":"","title":"Overview"},{"body":"","categories":"","description":"No description.\n","excerpt":"No description.\n","ref":"/zh/docs/overview/","tags":"","title":"Overview"},{"body":"","categories":"","description":"This page tells you how to get started with the devlake.\n","excerpt":"This page tells you how to get started with the devlake.\n","ref":"/docs/quick-start/","tags":"","title":"Quick Start"},{"body":"","categories":"","description":"This page tells you how to get started with the devlake.\n","excerpt":"This page tells you how to get started with the devlake.\n","ref":"/zh/docs/quick-start/","tags":"","title":"Quick Start"},{"body":" Collect data from mainstream DevOps tools, including Jira (Cloud), Jira Server v8+, Git, GitLab, GitHub, Jenkins etc., supported by plugins. Receive data through Push API. Standardize DevOps data based on domain layer schema. Support 20+ built-in engineering metrics to observe productivity, quality and delivery capability. Connect “commit” entity with “issue” entity, and generate composite metrics such as Bugs Count per 1k Lines of Code. Identify new commits based on RefDiff plugin, and analyze productivity and quality of each version. Flexible dashboards to support data visualization and queries, based on Grafana.  \n","categories":"","description":"Features of the latest version of DevLake.\n","excerpt":"Features of the latest version of DevLake.\n","ref":"/docs/features/","tags":"","title":"Features"},{"body":" Collect data from mainstream DevOps tools, including Jira (Cloud), Jira Server v8+, Git, GitLab, GitHub, Jenkins etc., supported by plugins. Receive data through Push API. Standardize DevOps data based on domain layer schema. Support 20+ built-in engineering metrics to observe productivity, quality and delivery capability. Connect “commit” entity with “issue” entity, and generate composite metrics such as Bugs Count per 1k Lines of Code. Identify new commits based on RefDiff plugin, and analyze productivity and quality of each version. Flexible dashboards to support data visualization and queries, based on Grafana.  \n","categories":"","description":"Features of the latest version of DevLake.\n","excerpt":"Features of the latest version of DevLake.\n","ref":"/zh/docs/features/","tags":"","title":"Features"},{"body":"  Category Metric Name Definition Data Required Use Scenarios and Recommended Practices Value               Delivery Velocity Requirement Count Number of issues in type \"Requirement\" Issue/Task Management entities: Jira issues, GitHub issues, etc 1. Analyze the number of requirements and delivery rate of different time cycles to find the stability and trend of the development process. 2. Analyze and compare the number of requirements delivered and delivery rate of each project/team, and compare the scale of requirements of different projects. 3. Based on historical data, establish a baseline of the delivery capacity of a single iteration (optimistic, probable and pessimistic values) to provide a reference for iteration estimation. 4. Drill down to analyze the number and percentage of requirements in different phases of SDLC. Analyze rationality and identify the requirements stuck in the backlog. 1. Based on historical data, establish a baseline of the delivery capacity of a single iteration to improve the organization and planning of R\u0026D resources. 2. Evaluate whether the delivery capacity matches the business phase and demand scale. Identify key bottlenecks and reasonably allocate resources.   Requirement Delivery Rate Ratio of delivered requirements to all requirements Issue/Task Management entities: Jira issues, GitHub issues, etc   Requirement Lead Time Lead time of issues with type \"Requirement\" Issue/Task Management entities: Jira issues, GitHub issues, etc  1. Analyze the trend of requirement lead time to observe if it has improved over time. 2. Analyze and compare the requirement lead time of each project/team to identify key projects with abnormal lead time. 3. Drill down to analyze a requirement's staying time in different phases of SDLC. Analyze the bottleneck of delivery velocity and improve the workflow. 1. Analyze key projects and critical points, identify good/to-be-improved practices that affect requirement lead time, and reduce the risk of delays 2. Focus on the end-to-end velocity of value delivery process; coordinate different parts of R\u0026D to avoid efficiency shafts; make targeted improvements to bottlenecks.   Requirement Granularity Number of story points associated with an issue Issue/Task Management entities: Jira issues, GitHub issues, etc  1. Analyze the story points/requirement lead time of requirements to evaluate whether the ticket size, ie. requirement complexity is optimal. 2. Compare the estimated requirement granularity with the actual situation and evaluate whether the difference is reasonable by combining more microscopic workload metrics (e.g. lines of code/code equivalents) 1. Promote product teams to split requirements carefully, improve requirements quality, help developers understand requirements clearly, deliver efficiently and with high quality, and improve the project management capability of the team. 2. Establish a data-supported workload estimation model to help R\u0026D teams calibrate their estimation methods and more accurately assess the granularity of requirements, which is useful to achieve better issue planning in project management.   Commit Count Number of Commits Source Code Management entities: Git/GitHub/GitLab commits  1. Identify the main reasons for the unusual number of commits and the possible impact on the number of commits through comparison 2. Evaluate whether the number of commits is reasonable in conjunction with more microscopic workload metrics (e.g. lines of code/code equivalents) 1. Identify potential bottlenecks that may affect output 2. Encourage R\u0026D practices of small step submissions and develop excellent coding habits   Added Lines of Code Accumulated number of added lines of code Source Code Management entities: Git/GitHub/GitLab commits 1. From the project/team dimension, observe the accumulated change in Added lines to assess the team activity and code growth rate 2. From version cycle dimension, observe the active time distribution of code changes, and evaluate the effectiveness of project development model. 3. From the member dimension, observe the trend and stability of code output of each member, and identify the key points that affect code output by comparison. 1. identify potential bottlenecks that may affect the output 2. Encourage the team to implement a development model that matches the business requirements; develop excellent coding habits   Deleted Lines of Code Accumulated number of deleted lines of code Source Code Management entities: Git/GitHub/GitLab commits   Pull Request Review Time Time from Pull/Merge created time until merged Source Code Management entities: GitHub PRs, GitLab MRs, etc  1. Observe the mean and distribution of code review time from the project/team/individual dimension to assess the rationality of the review time 1. Take inventory of project/team code review resources to avoid lack of resources and backlog of review sessions, resulting in long waiting time 2. Encourage teams to implement an efficient and responsive code review mechanism   Bug Age Lead time of issues in type \"Bug\" Issue/Task Management entities: Jira issues, GitHub issues, etc 1. Observe the trend of bug age and locate the key reasons.\n2. According to the severity level, type (business, functional classification), affected module, source of bugs, count and observe the length of bug and incident age. 1. Help the team to establish an effective hierarchical response mechanism for bugs and incidents. Focus on the resolution of important problems in the backlog.\n2. Improve team's and individual's bug/incident fixing efficiency. Identify good/to-be-improved practices that affect bug age or incident age   Incident Age Lead time of issues in type \"Incident\" Issue/Task Management entities: Jira issues, GitHub issues, etc   Delivery Quality Pull Request Count Number of Pull/Merge Requests Source Code Management entities: GitHub PRs, GitLab MRs, etc 1. From the developer dimension, we evaluate the code quality of developers by combining the task complexity with the metrics related to the number of review passes and review rounds.\n2. From the reviewer dimension, we observe the reviewer's review style by taking into account the task complexity, the number of passes and the number of review rounds.\n3. From the project/team dimension, we combine the project phase and team task complexity to aggregate the metrics related to the number of review passes and review rounds, and identify the modules with abnormal code review process and possible quality risks. 1. Code review metrics are process indicators to provide quick feedback on developers' code quality\n2. Promote the team to establish a unified coding specification and standardize the code review criteria\n3. Identify modules with low-quality risks in advance, optimize practices, and precipitate into reusable knowledge and tools to avoid technical debt accumulation   Pull Request Pass Rate Ratio of Pull/Merge Review requests to merged Source Code Management entities: GitHub PRs, GitLab MRs, etc   Pull Request Review Rounds Number of cycles of commits followed by comments/final merge Source Code Management entities: GitHub PRs, GitLab MRs, etc   Pull Request Review Count Number of Pull/Merge Reviewers Source Code Management entities: GitHub PRs, GitLab MRs, etc 1. As a secondary indicator, assess the cost of labor invested in the code review process 1. Take inventory of project/team code review resources to avoid long waits for review sessions due to insufficient resource input   Bug Count Number of bugs found during testing Issue/Task Management entities: Jira issues, GitHub issues, etc 1. From the project or team dimension, observe the statistics on the total number of defects, the distribution of the number of defects in each severity level/type/owner, the cumulative trend of defects, and the change trend of the defect rate in thousands of lines, etc.\n2. From version cycle dimension, observe the statistics on the cumulative trend of the number of defects/defect rate, which can be used to determine whether the growth rate of defects is slowing down, showing a flat convergence trend, and is an important reference for judging the stability of software version quality\n3. From the time dimension, analyze the trend of the number of test defects, defect rate to locate the key items/key points\n4. Evaluate whether the software quality and test plan are reasonable by referring to CMMI standard values 1. Defect drill-down analysis to inform the development of design and code review strategies and to improve the internal QA process\n2. Assist teams to locate projects/modules with higher defect severity and density, and clean up technical debts\n3. Analyze critical points, identify good/to-be-improved practices that affect defect count or defect rate, to reduce the amount of future defects   Incident Count Number of Incidents found after shipping Source Code Management entities: GitHub PRs, GitLab MRs, etc   Bugs Count per 1k Lines of Code Amount of bugs per 1,000 lines of code Source Code Management entities: GitHub PRs, GitLab MRs, etc   Incidents Count per 1k Lines of Code Amount of incidents per 1,000 lines of code Source Code Management entities: GitHub PRs, GitLab MRs, etc   Delivery Cost Commit Author Count Number of Contributors who have committed code Source Code Management entities: Git/GitHub/GitLab commits 1. As a secondary indicator, this helps assess the labor cost of participating in coding 1. Take inventory of project/team R\u0026D resource inputs, assess input-output ratio, and rationalize resource deployment   Delivery Capability Build Count The number of builds started CI/CD entities: Jenkins PRs, GitLabCI MRs, etc 1. From the project dimension, compare the number of builds and success rate by combining the project phase and the complexity of tasks\n2. From the time dimension, analyze the trend of the number of builds and success rate to see if it has improved over time 1. As a process indicator, it reflects the value flow efficiency of upstream production and research links\n2. Identify excellent/to-be-improved practices that impact the build, and drive the team to precipitate reusable tools and mechanisms to build infrastructure for fast and high-frequency delivery   Build Duration The duration of successful builds CI/CD entities: Jenkins PRs, GitLabCI MRs, etc   Build Success Rate The percentage of successful builds CI/CD entities: Jenkins PRs, GitLabCI MRs, etc   ","categories":"","description":"The definition, values and data required for the 20+ engineering metrics supported by DevLake.\n","excerpt":"The definition, values and data required for the 20+ engineering …","ref":"/docs/engineeringmetrics/","tags":"","title":"Engineering Metrics"},{"body":"  Category Metric Name Definition Data Required Use Scenarios and Recommended Practices Value               Delivery Velocity Requirement Count Number of issues in type \"Requirement\" Issue/Task Management entities: Jira issues, GitHub issues, etc 1. Analyze the number of requirements and delivery rate of different time cycles to find the stability and trend of the development process. 2. Analyze and compare the number of requirements delivered and delivery rate of each project/team, and compare the scale of requirements of different projects. 3. Based on historical data, establish a baseline of the delivery capacity of a single iteration (optimistic, probable and pessimistic values) to provide a reference for iteration estimation. 4. Drill down to analyze the number and percentage of requirements in different phases of SDLC. Analyze rationality and identify the requirements stuck in the backlog. 1. Based on historical data, establish a baseline of the delivery capacity of a single iteration to improve the organization and planning of R\u0026D resources. 2. Evaluate whether the delivery capacity matches the business phase and demand scale. Identify key bottlenecks and reasonably allocate resources.   Requirement Delivery Rate Ratio of delivered requirements to all requirements Issue/Task Management entities: Jira issues, GitHub issues, etc   Requirement Lead Time Lead time of issues with type \"Requirement\" Issue/Task Management entities: Jira issues, GitHub issues, etc  1. Analyze the trend of requirement lead time to observe if it has improved over time. 2. Analyze and compare the requirement lead time of each project/team to identify key projects with abnormal lead time. 3. Drill down to analyze a requirement's staying time in different phases of SDLC. Analyze the bottleneck of delivery velocity and improve the workflow. 1. Analyze key projects and critical points, identify good/to-be-improved practices that affect requirement lead time, and reduce the risk of delays 2. Focus on the end-to-end velocity of value delivery process; coordinate different parts of R\u0026D to avoid efficiency shafts; make targeted improvements to bottlenecks.   Requirement Granularity Number of story points associated with an issue Issue/Task Management entities: Jira issues, GitHub issues, etc  1. Analyze the story points/requirement lead time of requirements to evaluate whether the ticket size, ie. requirement complexity is optimal. 2. Compare the estimated requirement granularity with the actual situation and evaluate whether the difference is reasonable by combining more microscopic workload metrics (e.g. lines of code/code equivalents) 1. Promote product teams to split requirements carefully, improve requirements quality, help developers understand requirements clearly, deliver efficiently and with high quality, and improve the project management capability of the team. 2. Establish a data-supported workload estimation model to help R\u0026D teams calibrate their estimation methods and more accurately assess the granularity of requirements, which is useful to achieve better issue planning in project management.   Commit Count Number of Commits Source Code Management entities: Git/GitHub/GitLab commits  1. Identify the main reasons for the unusual number of commits and the possible impact on the number of commits through comparison 2. Evaluate whether the number of commits is reasonable in conjunction with more microscopic workload metrics (e.g. lines of code/code equivalents) 1. Identify potential bottlenecks that may affect output 2. Encourage R\u0026D practices of small step submissions and develop excellent coding habits   Added Lines of Code Accumulated number of added lines of code Source Code Management entities: Git/GitHub/GitLab commits 1. From the project/team dimension, observe the accumulated change in Added lines to assess the team activity and code growth rate 2. From version cycle dimension, observe the active time distribution of code changes, and evaluate the effectiveness of project development model. 3. From the member dimension, observe the trend and stability of code output of each member, and identify the key points that affect code output by comparison. 1. identify potential bottlenecks that may affect the output 2. Encourage the team to implement a development model that matches the business requirements; develop excellent coding habits   Deleted Lines of Code Accumulated number of deleted lines of code Source Code Management entities: Git/GitHub/GitLab commits   Pull Request Review Time Time from Pull/Merge created time until merged Source Code Management entities: GitHub PRs, GitLab MRs, etc  1. Observe the mean and distribution of code review time from the project/team/individual dimension to assess the rationality of the review time 1. Take inventory of project/team code review resources to avoid lack of resources and backlog of review sessions, resulting in long waiting time 2. Encourage teams to implement an efficient and responsive code review mechanism   Bug Age Lead time of issues in type \"Bug\" Issue/Task Management entities: Jira issues, GitHub issues, etc 1. Observe the trend of bug age and locate the key reasons.\n2. According to the severity level, type (business, functional classification), affected module, source of bugs, count and observe the length of bug and incident age. 1. Help the team to establish an effective hierarchical response mechanism for bugs and incidents. Focus on the resolution of important problems in the backlog.\n2. Improve team's and individual's bug/incident fixing efficiency. Identify good/to-be-improved practices that affect bug age or incident age   Incident Age Lead time of issues in type \"Incident\" Issue/Task Management entities: Jira issues, GitHub issues, etc   Delivery Quality Pull Request Count Number of Pull/Merge Requests Source Code Management entities: GitHub PRs, GitLab MRs, etc 1. From the developer dimension, we evaluate the code quality of developers by combining the task complexity with the metrics related to the number of review passes and review rounds.\n2. From the reviewer dimension, we observe the reviewer's review style by taking into account the task complexity, the number of passes and the number of review rounds.\n3. From the project/team dimension, we combine the project phase and team task complexity to aggregate the metrics related to the number of review passes and review rounds, and identify the modules with abnormal code review process and possible quality risks. 1. Code review metrics are process indicators to provide quick feedback on developers' code quality\n2. Promote the team to establish a unified coding specification and standardize the code review criteria\n3. Identify modules with low-quality risks in advance, optimize practices, and precipitate into reusable knowledge and tools to avoid technical debt accumulation   Pull Request Pass Rate Ratio of Pull/Merge Review requests to merged Source Code Management entities: GitHub PRs, GitLab MRs, etc   Pull Request Review Rounds Number of cycles of commits followed by comments/final merge Source Code Management entities: GitHub PRs, GitLab MRs, etc   Pull Request Review Count Number of Pull/Merge Reviewers Source Code Management entities: GitHub PRs, GitLab MRs, etc 1. As a secondary indicator, assess the cost of labor invested in the code review process 1. Take inventory of project/team code review resources to avoid long waits for review sessions due to insufficient resource input   Bug Count Number of bugs found during testing Issue/Task Management entities: Jira issues, GitHub issues, etc 1. From the project or team dimension, observe the statistics on the total number of defects, the distribution of the number of defects in each severity level/type/owner, the cumulative trend of defects, and the change trend of the defect rate in thousands of lines, etc.\n2. From version cycle dimension, observe the statistics on the cumulative trend of the number of defects/defect rate, which can be used to determine whether the growth rate of defects is slowing down, showing a flat convergence trend, and is an important reference for judging the stability of software version quality\n3. From the time dimension, analyze the trend of the number of test defects, defect rate to locate the key items/key points\n4. Evaluate whether the software quality and test plan are reasonable by referring to CMMI standard values 1. Defect drill-down analysis to inform the development of design and code review strategies and to improve the internal QA process\n2. Assist teams to locate projects/modules with higher defect severity and density, and clean up technical debts\n3. Analyze critical points, identify good/to-be-improved practices that affect defect count or defect rate, to reduce the amount of future defects   Incident Count Number of Incidents found after shipping Source Code Management entities: GitHub PRs, GitLab MRs, etc   Bugs Count per 1k Lines of Code Amount of bugs per 1,000 lines of code Source Code Management entities: GitHub PRs, GitLab MRs, etc   Incidents Count per 1k Lines of Code Amount of incidents per 1,000 lines of code Source Code Management entities: GitHub PRs, GitLab MRs, etc   Delivery Cost Commit Author Count Number of Contributors who have committed code Source Code Management entities: Git/GitHub/GitLab commits 1. As a secondary indicator, this helps assess the labor cost of participating in coding 1. Take inventory of project/team R\u0026D resource inputs, assess input-output ratio, and rationalize resource deployment   Delivery Capability Build Count The number of builds started CI/CD entities: Jenkins PRs, GitLabCI MRs, etc 1. From the project dimension, compare the number of builds and success rate by combining the project phase and the complexity of tasks\n2. From the time dimension, analyze the trend of the number of builds and success rate to see if it has improved over time 1. As a process indicator, it reflects the value flow efficiency of upstream production and research links\n2. Identify excellent/to-be-improved practices that impact the build, and drive the team to precipitate reusable tools and mechanisms to build infrastructure for fast and high-frequency delivery   Build Duration The duration of successful builds CI/CD entities: Jenkins PRs, GitLabCI MRs, etc   Build Success Rate The percentage of successful builds CI/CD entities: Jenkins PRs, GitLabCI MRs, etc   ","categories":"","description":"The definition, values and data required for the 20+ engineering metrics supported by DevLake.\n","excerpt":"The definition, values and data required for the 20+ engineering …","ref":"/zh/docs/engineeringmetrics/","tags":"","title":"Engineering Metrics"},{"body":"","categories":"","description":"","excerpt":"","ref":"/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/categories/","tags":"","title":"Categories"},{"body":"","categories":"","description":"","excerpt":"","ref":"/community/","tags":"","title":"Community"},{"body":"   #td-cover-block-0 { background-image: url(/featured-background_hu06d16800a0f7294a8c2040f130cb8b45_1710855_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/featured-background_hu06d16800a0f7294a8c2040f130cb8b45_1710855_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to DevLake  Quick start   GitHub   Make better sense of your software development process by ingesting, analyzing, and visualizing data from an ever-growing list of developer tools\n                 Silos Connected Collect DevOps data across the entire SDLC process and connect data silos\n    Out-of-the-box Analysis A standard data model and out-of-the-box metrics for software engineering\n    Highly Flexible Flexible framework for data collection and ETL, support customized analysis\n      ","categories":"","description":"","excerpt":"   #td-cover-block-0 { background-image: …","ref":"/","tags":"","title":"DevLake"},{"body":"   #td-cover-block-0 { background-image: url(/zh/featured-background_hu06d16800a0f7294a8c2040f130cb8b45_1710855_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/zh/featured-background_hu06d16800a0f7294a8c2040f130cb8b45_1710855_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to DevLake Quick start   GitHub    Make better sense of your software development process by ingesting, analyzing, and visualizing data from an ever-growing list of developer tools\n                 Silos Connected Collect DevOps data across the entire SDLC process and connect data silos\n    Out-of-the-box Analysis A standard data model and out-of-the-box metrics for software engineering\n    Highly Flexible Flexible framework for data collection and ETL, support customized analysis\n      ","categories":"","description":"","excerpt":"   #td-cover-block-0 { background-image: …","ref":"/zh/","tags":"","title":"DevLake"},{"body":"","categories":"","description":"","excerpt":"","ref":"/docs/","tags":"","title":"Documentation"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/docs/","tags":"","title":"Documentation（假装都是中文）"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tags/","tags":"","title":"Tags"},{"body":"","categories":"","description":"","excerpt":"","ref":"/zh/tags/","tags":"","title":"Tags"},{"body":" Contributing to Lake 👍🎉 First off, thanks for taking the time to contribute! 🎉👍\nThe following is a set of guidelines for contributing to Lake. These are mostly guidelines, not rules. Use your best judgment, and feel free to propose changes to this document in a pull request.*\n       How Can I Contribute?   Reporting bugs by filling out the required issue template and labeling the new issue as ‘bug’.\n  Suggesting enhancements.\n  If you intend to change the public API, or make any non-trivial changes to the implementation, we recommend filing an issue. This lets us reach an agreement on your proposal before you put significant effort into it.\nIf you’re only fixing a bug, it’s fine to submit a pull request right away but we still recommend to file an issue detailing what you’re fixing. This is helpful in case we don’t accept that specific fix but want to keep track of the issue.\n    Maintainer team @ Merico Dev Lake is maintained by a group of engineers at Merico, led by @hezyin. We aim to achieve an SLA of 24 hrs for replying to issues.\nStyle guides Git Commit message We follow the conventional commits guidelines.\nCommit tool We use https://github.com/lintingzhen/commitizen-go to author our commits.\n   ","categories":"","description":"","excerpt":" Contributing to Lake 👍🎉 First off, thanks for taking the time to …","ref":"/zh/community/","tags":"","title":"社区"}]